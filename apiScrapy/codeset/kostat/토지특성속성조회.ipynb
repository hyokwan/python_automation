{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963ade77-ae0c-408d-930a-14e1b15edc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## 1. 필요 라이브러리 선언\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.chdir('C:/Users/luthe/Desktop/python_automation-master/apiScrapy/codeset/kostat')\n",
    "#os.chdir('/data/KITECH/apiScrapy/codeset/kostat/')\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"./\"))))\n",
    "from common import commonFunc as cf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import gc\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b23341-f8b5-4a2c-85a1-ca61babd2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. 필요 변수 선언\n",
    "\n",
    "# ### 2-1. 메타데이터 업로드\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "metadata = pd.read_excel(\"../../input/datalake_meta22.xlsx\", sheet_name=\"3. 통계청\",engine=\"openpyxl\")\n",
    "\n",
    "\n",
    "# ### 2-2. output 폴더 생성 변수\n",
    "SITENAME = \"kostat\"\n",
    "DATANAME= \"토지특성속성조회\"\n",
    "targetData = metadata.loc[metadata.자료명==DATANAME]\n",
    "SERVICENAME = targetData[\"서비스키\"].values[0].split(\".\")[0]\n",
    "\n",
    "org_data = pd.DataFrame()\n",
    "try:\n",
    "    # 기존 데이터 및 파라미터 정보 불러오기\n",
    "    org_data = cf.loadparam(SITENAME,DATANAME,SERVICENAME)\n",
    "## 파일이 없는경우\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "tot_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526ea8d-8f2d-477d-92ba-450d7e65b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 2-3. 기본키 설정\n",
    "# #### 1) API KEY\n",
    "with open(\"../../input/ppsapikey.pickle\",\"rb\") as fr:\n",
    "        ServiceKeyLst = pickle.load(fr)\n",
    "\n",
    "pnuDf = pd.read_csv(\"./행정구역코드(법정동코드).csv\", encoding=\"ms949\")\n",
    "pnuList = pnuDf.loc[pnuDf.폐지여부 == \"존재\"].법정동코드.values.tolist()\n",
    "\n",
    "numOfRows = \"999\"\n",
    "\n",
    "BASEPARAM_KEY = targetData.기본키.values[0].split(\",\")\n",
    "BASEPARAM_Lst = []\n",
    "\n",
    "BASEPARAM_VAL = [numOfRows]\n",
    "\n",
    "for i in range(len(pnuList)):\n",
    "    BASEPARAM = {}\n",
    "    BASEPARAM_VAL.append(pnuList[i])\n",
    "    for j in range(len(BASEPARAM_VAL)):\n",
    "        BASEPARAM[BASEPARAM_KEY[j]] = BASEPARAM_VAL[j]\n",
    "    BASEPARAM_Lst.append(BASEPARAM)\n",
    "    BASEPARAM_VAL.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a95cb-6492-4366-b3ce-df40d04971fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 2-4. 함수 파라미터\n",
    "URL = targetData[\"URL\"].values[0]\n",
    "PAGEYN=1\n",
    "STDENCODING='utf-8'\n",
    "APICALL=0\n",
    "inType = \"xml\"\n",
    "mode = 1\n",
    "jsonkey = \"field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e92e54-4246-4cdf-b1ce-5f50db77ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. 데이터 수집\n",
    "# ### 3-2. 데이터 수집\n",
    "breakPoint = 0\n",
    "# ## 가) 초기 인증키를 통한 수집\n",
    "flag = False\n",
    "pageList = []\n",
    "dfList = []\n",
    "failList = []\n",
    "\n",
    "starttime = time.time()\n",
    "print(\"수집시작 : \", time.strftime('%c', time.localtime(time.time())))\n",
    "for i in range(len(ServiceKeyLst)):\n",
    "    if flag:\n",
    "        break\n",
    "    while (breakPoint < len(BASEPARAM_Lst)):\n",
    "        if breakPoint == len(BASEPARAM_Lst) - 1:\n",
    "            flag = True\n",
    "        try:\n",
    "            BASEPARAM_Lst[breakPoint][\"ServiceKey\"] = ServiceKeyLst[i]\n",
    "            scrapyResult = cf.scrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM_Lst[breakPoint],PAGEYN,ServiceKeyLst,APICALL, jsonkey=jsonkey,inType=inType)\n",
    "            resultDf = scrapyResult[0]\n",
    "            if resultDf is None:\n",
    "                failList.append(BASEPARAM_Lst[breakPoint])\n",
    "                if breakPoint <= len(BASEPARAM_Lst) - 1:\n",
    "                    breakPoint=breakPoint+1\n",
    "                continue\n",
    "            elif type(resultDf) == pd.core.frame.DataFrame:\n",
    "                if resultDf.empty:\n",
    "                    failList.append(BASEPARAM_Lst[breakPoint])\n",
    "                    if breakPoint <= len(BASEPARAM_Lst) - 1:\n",
    "                        breakPoint=breakPoint+1\n",
    "                    continue\n",
    "            dfList.append(resultDf)\n",
    "            pageList.append(scrapyResult[1])\n",
    "            APICALL = scrapyResult[2]\n",
    "            tot_cnt = tot_cnt + scrapyResult[3]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if e.args[0] == \"22\" or e.args[0] == \"20\":\n",
    "                print(\"LIMITED_NUMBER_OF_SERVICE_REQUESTS_EXCEEDS_ERROR\")\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(10)\n",
    "        else:\n",
    "            if breakPoint <= len(BASEPARAM_Lst) - 1:\n",
    "                breakPoint=breakPoint+1\n",
    "\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c740a9-6504-4872-a30f-3f02d07b0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResultDf = pd.concat(dfList).reset_index(drop=True)\n",
    "\n",
    "completed = False\n",
    "data_chg_cnt = len(finalResultDf)\n",
    "\n",
    "if tot_cnt == data_chg_cnt or (tot_cnt != data_chg_cnt and len(failList) == 0):\n",
    "    completed = True\n",
    "    print(\"수집 종료 : \", time.time()-starttime)\n",
    "else:\n",
    "    print(\"수집 실패 : \", time.time()-starttime)\n",
    "\n",
    "if completed:\n",
    "    exit_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "    typical_col = ['ctgry_cd', 'ctgry_nm', 'phase_cd', 'phase_nm', 'lifecycle_cd',\n",
    "           'lifecycle_nm', 'clnt_cd', 'clnt_nm', 'biz_regst_num', 'cntrct_frm_nm',\n",
    "           'domain_cd', 'domain_nm', 'facility_cd', 'facility_nm',\n",
    "           'cnstrct_wrk_cd', 'cnstrct_wrk_nm', 'wbslv1_cd', 'wbslv1_nm',\n",
    "           'wbslv2_cd', 'wbslv2_nm', 'authrt_lv_cd', 'authrt_lv_nm', 'reg_ymd',\n",
    "           'end_ymd', 'strg_dir', 'strg_filename', 'data_src', 'ntwrk',\n",
    "           'clct_mthd', 'clmn_nm_hanguel', 'clmn_nm', 'preprcs', 'updt_cycle',\n",
    "           'req_url', 'svc_key', 'base_key', 'req_param', 'data_type']\n",
    "\n",
    "    dtype = {}\n",
    "\n",
    "    for each in typical_col:\n",
    "        dtype[each] = str\n",
    "\n",
    "    clc_typcial = pd.read_csv(\"../../../input/meta/clc_typical.csv\", names=typical_col, dtype=dtype)\n",
    "\n",
    "    index = clc_typcial[(clc_typcial.ctgry_nm == \"통계청\") & (clc_typcial.strg_filename == f'{DATANAME}.csv')].index.values[0]\n",
    "    clc_typcial.loc[index,\"reg_ymd\"] = exit_date\n",
    "\n",
    "    clc_typcial.to_csv(\"../../../input/meta/clc_typical.csv\", encoding=\"utf8\",index=False,header=False)\n",
    "\n",
    "    update_query = \"update experdba.prov_data set reg_ymd = '{0}' where ctgry_nm = '통계청' and strg_filename = '{1}.csv'\".format(exit_date, DATANAME)\n",
    "\n",
    "    try:\n",
    "        #  conn = psycopg2.connect(database=\"postgres\",user=\"postgres\",password=\"kopo\",host=\"localhost\",port=\"5432\")\n",
    "        conn = psycopg2.connect(database=\"experdb\", user=\"experdb\", password=\"experdb\", host=\"172.16.0.153\",\n",
    "                                port=\"5432\")\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        cur.execute(update_query)\n",
    "        #   cur.execute(del_query)\n",
    "        conn.commit()\n",
    "        print(\"execute success\")\n",
    "    except Exeception as e:\n",
    "        print(\"database connection error\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f520d2-4a93-46ba-b962-200e7bbaa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. 적재를 위한 테이블 가공 및 적재\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "data_tot_cnt = 0\n",
    "if completed:\n",
    "    columnNm = targetData.한글컬럼명.values[0].split(\",\")\n",
    "\n",
    "    finalResultDf.columns = columnNm\n",
    "\n",
    "    mergedDf = pd.DataFrame()\n",
    "\n",
    "    if not org_data.empty:\n",
    "        mergedDf = pd.concat([org_data, finalResultDf])\n",
    "    else:\n",
    "        mergedDf = pd.concat([org_data, finalResultDf])\n",
    "\n",
    "    del org_data\n",
    "    del finalResultDf\n",
    "    gc.collect()\n",
    "\n",
    "    mergedDf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cf.savedata(mergedDf, SITENAME, DATANAME, SERVICENAME)\n",
    "    cf.saveparam(mergedDf, SITENAME, DATANAME, SERVICENAME)\n",
    "\n",
    "    data_tot_cnt = len(mergedDf)\n",
    "# 수집실패했을경우에도 기존 org 데이터의 건수정보는 total_cnt에 저장한다.\n",
    "else:\n",
    "    data_tot_cnt = len(org_data)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "try:\n",
    "    engine = create_engine(\"postgresql://experdb:experdb@172.16.0.153:5432/experdb\", encoding='utf8')\n",
    "\n",
    "    conn_engine = engine.connect()\n",
    "\n",
    "    if completed:\n",
    "        exec_df = pd.DataFrame([{\"site_name\": SITENAME, \"pg_name\": DATANAME, \"data_upt_cnt\": data_chg_cnt,\n",
    "                                 \"data_tot_cnt\": data_tot_cnt,\n",
    "                                 \"exec_date\": datetime.fromtimestamp(end_time).strftime(\"%Y-%m-%d\"),\n",
    "                                 \"start_time\": datetime.fromtimestamp(starttime).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                 \"end_time\": datetime.fromtimestamp(end_time).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                 \"exec_time\": time.strftime('%H:%M:%S', time.gmtime(end_time - starttime)),\n",
    "                                 \"exec_yn\": 'Y'}])\n",
    "    else:\n",
    "        exec_df = pd.DataFrame([{\"site_name\": SITENAME, \"pg_name\": DATANAME, \"data_upt_cnt\": data_chg_cnt,\n",
    "                                 \"data_tot_cnt\": data_tot_cnt,\n",
    "                                 \"exec_date\": datetime.fromtimestamp(end_time).strftime(\"%Y-%m-%d\"),\n",
    "                                 \"start_time\": datetime.fromtimestamp(starttime).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                 \"end_time\": datetime.fromtimestamp(end_time).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                 \"exec_time\": time.strftime('%H:%M:%S', time.gmtime(end_time - starttime)),\n",
    "                                 \"exec_yn\": 'N'}])\n",
    "    exec_df.to_sql(\"prov_stat\", engine, if_exists=\"append\", index=False)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    conn_engine.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
