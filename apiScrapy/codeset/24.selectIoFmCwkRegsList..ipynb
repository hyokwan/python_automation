{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시설물 유지보수대장 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/건설사업정보시스템/시설물 유지보수대장 목록/selectIoFmCwkRegsList.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common import commonFunc as cf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "metadata = pd.read_excel(\"../input/datalake_meta22.xlsx\")\n",
    "\n",
    "SITENAME = \"건설사업정보시스템\"\n",
    "DATANAME= \"시설물 유지보수대장 목록\"\n",
    "with open(\"../input/calsapikey.pickle\",\"rb\") as fr:\n",
    "    APIKEY = pickle.load(fr)\n",
    "\n",
    "targetData = metadata.loc[metadata.자료명==DATANAME]\n",
    "preSetFolder = targetData[\"저장폴더\"].values[0]\n",
    "\n",
    "preSetFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 시설물 유지보수대장목록 수\n",
    "g_totalCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'selectIoFmCwkRegsList'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### 파라미터 설정 #####\n",
    "URL = targetData[\"URL\"].values[0]\n",
    "SERVICENAME = targetData[\"서비스키\"].values[0]\n",
    "SERVICENAME = SERVICENAME.split(\".\")[0]\n",
    "SERVICENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serviceKey',\n",
       " 'type',\n",
       " 'pageNo',\n",
       " 'numOfRows',\n",
       " 'sortField',\n",
       " 'sortOrder',\n",
       " 'searchCwkEdYr',\n",
       " 'searchCwkNm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REQPARAM = targetData[\"요청변수\"].values[0]\n",
    "REQPARAM = REQPARAM.split(\",\")\n",
    "PRIMARYKEY = targetData[\"기본키\"].values[0]\n",
    "REQPARAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 페이지번호 설정\n",
    "PAGEYN=1\n",
    "if REQPARAM.count(\"pageNo\") == 0:\n",
    "    PAGEYN = 0\n",
    "else:\n",
    "    PAGEYN = 1\n",
    "### 기본정보 설정 및 파라미터 설정 ###\n",
    "PAGEYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONKEY = \"items\"\n",
    "DUMMY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시설물 유지보수대장 목록 정보 new 모드 2 \n"
     ]
    }
   ],
   "source": [
    "newParam = []\n",
    "mode = 2\n",
    "if newParam==[]:\n",
    "    mode=2\n",
    "    print(\"{} 정보 new 모드 {} \".format(DATANAME, mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시설물 유지보수대장 목록 전용 스크랩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlencode, quote_plus, unquote\n",
    "import os\n",
    "\n",
    "STDENCODING=\"utf-8\"\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "### 파마리터정의: \n",
    "###   - inurl: 메타정보의 \"URL\"컬럼값 (예: https://www.calspia.go.kr/io/openapi/cm/selectIoCmConstructionList.do )\n",
    "###   - inSiteName: 메타정보의 \"자료대상\" (예: 건설사업정보시스템)\n",
    "###   - inDataName: 메타정보의 \"자료명\" (예: 공사정보 목록)\n",
    "###   - inServiceName: 메타정보의 \"기본키\" (예: serviceKey + Format)\n",
    "###   - inParam: 메타정보의 \"파라미터 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "###   - inPageYn: 메타정보의 \"페이지 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "def myscrapy(inUrl, inSiteName, inDataName, inServiceName, inParam, inPageYn, jsonkey=\"items\", dummy=0, inType=\"jsonabnormal\"):\n",
    "    try:\n",
    "        emptyPd = pd.DataFrame()\n",
    "        i=1\n",
    "        while True:\n",
    "            print(\"{} page scraping start\".format(i))\n",
    "            \n",
    "            if(inPageYn==1):\n",
    "                inParam[\"pageNo\"] = i\n",
    "            queryParams = '?' + urlencode(inParam)\n",
    "            requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "            response = requests.get(inUrl+queryParams,verify=False)\n",
    "            response.encoding=STDENCODING\n",
    "            rowData = pd.DataFrame()\n",
    "            if(inType==\"jsonabnormal\"):\n",
    "                # 비정상 데이터는 response 섹션이 없음\n",
    "                if(response.json().get('response') == None):\n",
    "                    jsondata = response.json()[\"header\"][\"resultMsg\"]\n",
    "                    if( jsondata != \"NORMAL_SERVICE\"):\n",
    "                        print(\"SERVER ERROR \",jsondata)\n",
    "                        break\n",
    "                \n",
    "                # 25번 도로시설물 관리현황 정보의 검색결과 패턴을 비교하였을때 items에만 결과를 줄 것으로 예상  \n",
    "                # 여기서부터는 데이터는 있는데, totalcount>0 경우는 items 정보에 세부정보가 더 있음\n",
    "                if(response.json()[\"response\"][\"body\"].get(jsonkey) == None):                  \n",
    "                    print(jsonkey+\"is None !!!!\")\n",
    "                    break\n",
    "                \n",
    "\n",
    "                print(\">totalCount \"+str(response.json()[\"response\"][\"body\"][\"totalCount\"]))\n",
    "                if(0 < int(response.json()[\"response\"][\"body\"][\"totalCount\"])):\n",
    "                    global g_totalCount\n",
    "                    if g_totalCount == 0:\n",
    "                        g_totalCount = int(response.json()[\"response\"][\"body\"][\"totalCount\"])\n",
    "                    jsondata = response.json()[\"response\"][\"body\"][jsonkey]\n",
    "                    if( jsondata == []):\n",
    "                        print(\"items is empty\")\n",
    "                    else:\n",
    "#                         jsondata[\"index\"]=[0]\n",
    "                        rowData = pd.DataFrame(jsondata)\n",
    "                        print(rowData)\n",
    "                        emptyPd = emptyPd.append(rowData)\n",
    "                    \n",
    "            else:\n",
    "                print(\"Error\")          \n",
    "     \n",
    "            if(inPageYn == 0):\n",
    "                print(\"{} no pageNo\".format(inPageYn))\n",
    "                break\n",
    "            i = i+1\n",
    "\n",
    "        emptyPd.columns = emptyPd.columns.str.lower()\n",
    "        emptyPd.shape\n",
    "#         print(\"dataframe{}, param:{} rows: {} completed\".format(inDataName,inParam, emptyPd.shape[1] )     )\n",
    "        return emptyPd       \n",
    "    except Exception as e:\n",
    "            print(e)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numOfRows = 1000\n",
    "pageNo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class noDataFound(Exception): pass  # declare a label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 page scraping start apicall iter: 1 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "1 page is empty\n",
      "dataframe시설물 유지보수대장 목록, param:{'serviceKey': '49099D1D-E565-48E1-8A6F-D5F47135EA34', 'pageNo': 1, 'numOfRows': 1000, 'type': 'json'} rows: 0 completed\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "resultDfMerged = pd.DataFrame()\n",
    "resultDf = pd.DataFrame()\n",
    "pageList = [] # 4/28 추가\n",
    "APICALL = 0 #4/28 추가\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    for i in range(0, 1):\n",
    "#         pageNo = 1\n",
    "#         global g_totalCount\n",
    "#         g_totalCount = 0\n",
    "#         print(\"i=\",i)\n",
    "\n",
    "        # 25번 도로시설물 관리현황 정보의 검색결과 패턴을 비교하였을때 items에만 결과를 줄 것으로 예상\n",
    "        BASEPARAM={\"serviceKey\":APIKEY[0],\"pageNo\": pageNo, 'numOfRows':numOfRows, \"type\":\"json\"}\n",
    "#             resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY)\n",
    "        scrapyResult = cf.scrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN,APIKEY,APICALL) #신규 4/28\n",
    "        resultDf = scrapyResult[0]\n",
    "        pageList.append( scrapyResult[1] )\n",
    "        APICALL = scrapyResult[2] \n",
    "        print(resultDf)\n",
    "        resultDfMerged = resultDfMerged.append(resultDf)\n",
    "            \n",
    "#             if resultDf.empty: # 정상 데이터가 없는 경우\n",
    "#                 print(\"NO DATA FOUND, CHECK CALS API\")\n",
    "#                 raise noDataFound()\n",
    "#             else:\n",
    "#                 resultDfMerged = resultDfMerged.append(resultDf) \n",
    "#                 g_totalCount -= numOfRows\n",
    "#                 print(\"g_totalCount : \", g_totalCount, \" numOfRows : \", numOfRows)\n",
    "#                 if(g_totalCount <= 0):\n",
    "#                     break\n",
    "#                 pageNo += 1\n",
    "        \n",
    "except noDataFound:\n",
    "    print(\"exception handled\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDfMerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시설물 유지보수대장 목록 save compled\n"
     ]
    }
   ],
   "source": [
    "cf.savedata(resultDfMerged, SITENAME,DATANAME,SERVICENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDfMerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
