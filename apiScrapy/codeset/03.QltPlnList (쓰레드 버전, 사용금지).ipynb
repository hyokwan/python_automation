{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 품질계획 현황 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import commonFunc as cf\n",
    "import pandas as pd\n",
    "import threading\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "metadata = pd.read_excel(\"../input/datalake_meta22.xlsx\")\n",
    "\n",
    "SITENAME = \"건설사업정보시스템\"\n",
    "DATANAME= \"품질계획 현황\"\n",
    "APIKEY = \"1EFCBE0D-3203-4485-A7BA-5F5DB2B476BF\"\n",
    "\n",
    "targetData = metadata.loc[metadata.자료명==DATANAME]\n",
    "preSetFolder = targetData[\"저장폴더\"].values[0]\n",
    "\n",
    "print(\"실행 금지\")\n",
    "exit()\n",
    "\n",
    "preSetFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 연도별 공사계약 목록에서  SPTNO 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임시 \n",
    "imsiDf = pd.read_csv(\\\n",
    "         \"../output/건설사업정보시스템/연도별 공사계약 목록/selectIoCmProjConstYearContractList.csv\", encoding=\"ms949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombi = imsiDf.loc[:,[\"sptno\"]].drop_duplicates()\n",
    "dfCombi.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombiLen = dfCombi.shape[0]\n",
    "dfCombiLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfThread = 10\n",
    "\n",
    "resultDfMerged = list(pd.DataFrame() for x in range(numOfThread))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 파라미터 설정 #####\n",
    "URL = targetData[\"URL\"].values[0]\n",
    "SERVICENAME = targetData[\"서비스키\"].values[0]\n",
    "SERVICENAME = SERVICENAME.split(\".\")[0]\n",
    "SERVICENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQPARAM = targetData[\"요청변수\"].values[0]\n",
    "REQPARAM = REQPARAM.split(\",\")\n",
    "PRIMARYKEY = targetData[\"기본키\"].values[0]\n",
    "PRIMARYKEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONKEY = \"detail1\"\n",
    "DUMMY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 페이지번호 설정 ###\n",
    "PAGEYN=1\n",
    "if REQPARAM.count(\"pageyn\") == 0:\n",
    "    PAGEYN = 0\n",
    "else:\n",
    "    PAGEYN = 1\n",
    "PAGEYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보고년월 기간을 추출하기 위한 커스텀 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# d1, d2 : datetime format \n",
    "# d1 >= d2\n",
    "def calc_month(d1, d2):\n",
    "    return (d1.year - d2.year) * 12 + (d1.month - d2.month + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 품질계획 현황 전용 스크랩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlencode, quote_plus, unquote\n",
    "import os\n",
    "\n",
    "STDENCODING=\"utf-8\"\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "### 파마리터정의: \n",
    "###   - inurl: 메타정보의 \"URL\"컬럼값 (예: https://www.calspia.go.kr/io/openapi/cm/selectIoCmConstructionList.do )\n",
    "###   - inSiteName: 메타정보의 \"자료대상\" (예: 건설사업정보시스템)\n",
    "###   - inDataName: 메타정보의 \"자료명\" (예: 공사정보 목록)\n",
    "###   - inServiceName: 메타정보의 \"기본키\" (예: serviceKey + Format)\n",
    "###   - inParam: 메타정보의 \"파라미터 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "###   - inPageYn: 메타정보의 \"페이지 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "def myscrapy(inUrl, inSiteName, inDataName, inServiceName, inParam, inPageYn, jsonkey=\"items\", dummy=0, inType=\"jsonabnormal\"):\n",
    "    try:\n",
    "        emptyPd = pd.DataFrame()\n",
    "        i=1\n",
    "        while True:\n",
    "            print(\"{} page scraping start\".format(i))\n",
    "            \n",
    "            if(inPageYn==1):\n",
    "                inParam[\"pageNo\"] = i\n",
    "            queryParams = '?' + urlencode(inParam)\n",
    "            requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "            response = requests.get(inUrl+queryParams, verify=False)\n",
    "            response.encoding=STDENCODING\n",
    "            rowData = pd.DataFrame()\n",
    "            if(inType==\"jsonabnormal\"):\n",
    "                # 비정상 데이터는 response 섹션이 없음\n",
    "                if(response.json().get('response') == None):\n",
    "                    jsondata = response.json()[\"header\"][\"resultMsg\"]\n",
    "                    if( jsondata != \"NORMAL_SERVICE\"):\n",
    "                        print(\"{} page is empty\".format(i))\n",
    "                        break\n",
    "                    \n",
    "#               여기서부터는 데이터는 있는데, totalcount>0 경우는 detailList1~5까지 봐야 한다.\n",
    "               \n",
    "                jsondata = response.json()[\"response\"][\"body\"][jsonkey]\n",
    "                if( jsondata == []):\n",
    "                    print(\"{} page is empty\".format(i))\n",
    "                    break\n",
    "                if( jsonkey == \"detail1\"):\n",
    "                    jsondata[\"index\"]=[0]\n",
    "                rowData = pd.DataFrame(jsondata)\n",
    "                emptyPd = emptyPd.append(rowData)\n",
    "                print(\">totalCount \"+str(response.json()[\"response\"][\"body\"][\"totalCount\"]))\n",
    "                if(0 < int(response.json()[\"response\"][\"body\"][\"totalCount\"])):\n",
    "                    if(response.json()[\"response\"][\"body\"].get('detailList1') != None):\n",
    "                        print(\"we have a data on detailList1\")\n",
    "                        jsondataDetail = response.json()[\"response\"][\"body\"][\"detailList1\"]\n",
    "\n",
    "                    elif(response.json()[\"response\"][\"body\"].get('detailList2') != None):\n",
    "                        jsondataDetail = response.json()[\"response\"][\"body\"][\"detailList2\"]\n",
    "                        print(\"we have a data on detailList2\")\n",
    "\n",
    "                    elif(response.json()[\"response\"][\"body\"].get('detailList3') != None):\n",
    "                        jsondataDetail = response.json()[\"response\"][\"body\"][\"detailList3\"]\n",
    "                        print(\"we have a data on detailList3\")\n",
    "\n",
    "                    elif(response.json()[\"response\"][\"body\"].get('detailList4') != None):\n",
    "                        jsondataDetail = response.json()[\"response\"][\"body\"][\"detailList4\"]\n",
    "                        print(\"we have a data on detailList4\")\n",
    "\n",
    "                    elif(response.json()[\"response\"][\"body\"].get('detailList5') != None):\n",
    "                        jsondataDetail = response.json()[\"response\"][\"body\"][\"detailList5\"]\n",
    "                        print(\"we have a data on detailList5\")\n",
    "#                     print(jsondataDetail)\n",
    "                    rowDataDetail = pd.DataFrame(jsondataDetail)\n",
    "                    emptyPd = pd.merge(emptyPd, rowDataDetail, on='sptNo')\n",
    "            else:\n",
    "                print(\"Error\")          \n",
    "     \n",
    "            if(inPageYn == 0):\n",
    "                print(\"{} no pageNo\".format(inPageYn))\n",
    "                break\n",
    "            i = i+1\n",
    "\n",
    "        emptyPd.columns = emptyPd.columns.str.lower()\n",
    "        emptyPd.shape\n",
    "#         print(\"dataframe{}, param:{} rows: {} completed\".format(inDataName,inParam, emptyPd.shape[1] )     )\n",
    "        return emptyPd       \n",
    "    except Exception as e:\n",
    "            print(e)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "resultDfMerged = pd.DataFrame()\n",
    "resultDf = pd.DataFrame()\n",
    "\n",
    "BASEPARAM={\"serviceKey\":APIKEY,\"sptNo\": sptnoValue, \"rprtYm\": \"\", \"type\":\"json\"}\n",
    "resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY)\n",
    "if resultDf.empty: # 정상 데이터가 없는 경우\n",
    "    print(\"No Data\")\n",
    "else:\n",
    "    tmpStartDay = resultDf[\"stwrdt\"].values[0].split('-')\n",
    "    tmpEndDay = resultDf[\"ccwdt\"].values[0].split('-')\n",
    "\n",
    "    dateRange = pd.period_range(resultDf[\"stwrdt\"].values[0],resultDf[\"ccwdt\"].values[0],freq='M').strftime('%Y%m').tolist()\n",
    "    print(dateRange)\n",
    "    for i in range(0,len(dateRange)):\n",
    "        BASEPARAM={\"serviceKey\":APIKEY,\"sptNo\": sptnoValue, \"rprtYm\": str(dateRange[i]), \"type\":\"json\"}\n",
    "        resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY)\n",
    "        resultDfMerged = resultDfMerged.append(resultDf) \n",
    "        print(\"----------------------------------------\")\n",
    "        print(resultDf)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()\n",
    "def threadReq(startIdx, endIdx,x):\n",
    "    resultDf = pd.DataFrame()\n",
    "    global resultDfMerged\n",
    "\n",
    "    for i in range(startIdx,endIdx):\n",
    "        sptnoValue = dfCombi.loc[i].sptno\n",
    "        BASEPARAM={\"serviceKey\":APIKEY,\"sptNo\": sptnoValue, \"rprtYm\": \"\", \"type\":\"json\"}\n",
    "        resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY)\n",
    "        print(\"i= \",i)\n",
    "        if resultDf.empty: # 정상 데이터가 없는 경우\n",
    "            print(\"No Data\")\n",
    "        else:\n",
    "            dateRange = pd.period_range(resultDf[\"stwrdt\"].values[0],resultDf[\"ccwdt\"].values[0],freq='M').strftime('%Y%m').tolist()\n",
    "            for i in range(0,len(dateRange)):\n",
    "                BASEPARAM={\"serviceKey\":APIKEY,\"sptNo\": sptnoValue, \"rprtYm\": str(dateRange[i]), \"type\":\"json\"}\n",
    "                resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY)\n",
    "                lock.acquire()\n",
    "                resultDfMerged[x] = resultDfMerged[x].append(resultDf) \n",
    "                lock.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultDfLastMerged = pd.DataFrame()\n",
    "section = list(range(0, dfCombiLen, int(dfCombiLen/numOfThread))) # we have \"numOfThread +1\" sections\n",
    "\n",
    "# dfCombiLen = 6 # for test\n",
    "if dfCombiLen < numOfThread:\n",
    "    print(\"데이터의 갯수가 적어서 쓰레드를 시작할 수 없습니다.\")\n",
    "else:\n",
    "    x_ls =list(range(numOfThread))\n",
    "    thread_list = []\n",
    "    results = []\n",
    "\n",
    "    for x in x_ls:\n",
    "        startIdx = section[x]\n",
    "        endIdx =  section[x+1] -1 if (x+1 <= numOfThread -1) else dfCombiLen - 1\n",
    "        print(\"start \",startIdx, \" end \",endIdx)\n",
    "        mythread = threading.Thread(target=threadReq, args=(startIdx, endIdx+1,x))\n",
    "        thread_list.append(mythread)\n",
    "    for i in thread_list:\n",
    "        i.start()\n",
    "    for i in thread_list:\n",
    "        i.join()\n",
    "    for i in range(0,numOfThread):\n",
    "        resultDfLastMerged = resultDfLastMerged.append(resultDfMerged[i]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,numOfThread):\n",
    "#     resultDfLastMerged = resultDfLastMerged.append(resultDfMerged[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TEST] \n",
    "# resultDfMerged = list(pd.DataFrame())\n",
    "# data = [1,2,3,4,5]\n",
    "# mypd = pd.DataFrame(data)\n",
    "# resultDfMerged.append(mypd)\n",
    "# resultDfMerged.append(mypd)\n",
    "# resultDfMerged.append(mypd)\n",
    "# resultDfMerged[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 쓰레드 사용하지 않는 기존 코드\n",
    "# for i in range(0,dfCombiLen):\n",
    "#     sptnoValue = dfCombi.loc[i].sptno\n",
    "#     BASEPARAM={\"serviceKey\":APIKEY,\"sptNo\": sptnoValue, \"rprtYm\": \"\", \"type\":\"json\"}\n",
    "#     resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY)\n",
    "#     print(\"i= \",i)\n",
    "#     if resultDf.empty: # 정상 데이터가 없는 경우\n",
    "#         print(\"No Data\")\n",
    "#     else:\n",
    "# #         tmpStartDay = resultDf[\"stwrdt\"].values[0].split('-')\n",
    "# #         tmpEndDay = resultDf[\"ccwdt\"].values[0].split('-')\n",
    "\n",
    "#         dateRange = pd.period_range(resultDf[\"stwrdt\"].values[0],resultDf[\"ccwdt\"].values[0],freq='M').strftime('%Y%m').tolist()\n",
    "#         print(dateRange)\n",
    "#         for i in range(0,len(dateRange)):\n",
    "#             BASEPARAM={\"serviceKey\":APIKEY,\"sptNo\": sptnoValue, \"rprtYm\": str(dateRange[i]), \"type\":\"json\"}\n",
    "#             resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY)\n",
    "#             resultDfMerged = resultDfMerged.append(resultDf) \n",
    "# #             print(\"----------------------------------------\")\n",
    "# #             print(resultDf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDfLastMerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.savedata(resultDfLastMerged, SITENAME,DATANAME,SERVICENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDfLastMerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
