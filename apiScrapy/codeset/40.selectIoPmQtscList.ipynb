{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 품질검사성적서 등록 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/건설사업정보시스템/품질검사성적서 등록 목록/selectIoPmQtscList.csv'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common import commonFunc as cf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)\n",
    "metadata = pd.read_excel(\"../input/datalake_meta22.xlsx\")\n",
    "\n",
    "SITENAME = \"건설사업정보시스템\"\n",
    "DATANAME= \"품질검사성적서 등록 목록\"\n",
    "### APIKEY 불러오기 ###\n",
    "with open(\"../input/calsapikey.pickle\",\"rb\") as fr:\n",
    "    APIKEY = pickle.load(fr)\n",
    "\n",
    "targetData = metadata.loc[metadata.자료명==DATANAME]\n",
    "preSetFolder = targetData[\"저장폴더\"].values[0]\n",
    "\n",
    "preSetFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKEYLEN = len(APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetData = metadata.loc[metadata.자료명==DATANAME]\n",
    "\n",
    "##### 파라미터 설정 #####\n",
    "URL = targetData[\"URL\"].values[0]\n",
    "SERVICENAME = targetData[\"서비스키\"].values[0]\n",
    "SERVICENAME = SERVICENAME.split(\".\")[0]\n",
    "REQPARAM = targetData[\"요청변수\"].values[0]\n",
    "REQPARAM = REQPARAM.split(\",\")\n",
    "PRIMARYKEY = targetData[\"기본키\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONKEY = \"items\"\n",
    "DUMMY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 페이지번호 설정 ###\n",
    "PAGEYN=1\n",
    "if REQPARAM.count(\"pageyn\") == 0:\n",
    "    PAGEYN = 0\n",
    "else:\n",
    "    PAGEYN = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 입력 파라미터 정보 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임시 \n",
    "imsiDf = pd.read_csv(\\\n",
    "         \"../output/건설사업정보시스템/건설자재 품질검사 등록정보/selectIoPmQtlTsitStsList.csv\",low_memory=False, encoding=\"ms949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74882"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCombi = imsiDf.loc[:,[\"cstrnm\"]].drop_duplicates()\n",
    "dfCombi.reset_index(inplace=True, drop=True)\n",
    "dfCombiLen = dfCombi.shape[0]\n",
    "dfCombiLen\n",
    "#mydf = dfCombi.cstrnm ==\"(주)디제이 종합건설\"\n",
    "#dfCombi[mydf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveLastSearchDate(paramStartDate):\n",
    "    cf.saveparam(paramStartDate, SITENAME, DATANAME, SERVICENAME+\"_LASTSEARCHDATE\")\n",
    "    print(\"Last Search Date {} is saved.\".format(paramStartDate))\n",
    "def loadLastSearchDate():\n",
    "    ret = cf.loadparam(SITENAME, DATANAME, SERVICENAME+\"_LASTSEARCHDATE\")\n",
    "    print(ret+\" is loaded\")\n",
    "    return ret\n",
    "def saveLastSearchDateByName(resultDf):\n",
    "    cf.savedata(resultDf, SITENAME,DATANAME,SERVICENAME+\"_LastSearchDateByName\")\n",
    "    print(\"Last Search Date {} is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 04 28\n",
      "20220427 is loaded\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "currentDateTime = datetime.datetime.now()\n",
    "date = currentDateTime.date()\n",
    "endYr = date.strftime(\"%Y\")\n",
    "endMonth = date.strftime(\"%m\")\n",
    "endDay = date.strftime(\"%d\")\n",
    "# 2001년 이전 데이터는 없음, 초기 데이터 수신 후 이후부터는 \n",
    "# 시작점(startDate): 이전 검색일\n",
    "# 종료점(endDate): 검색 당년.당월.당일 로 셋팅해야 함\n",
    "startYr = 2001 \n",
    "print(\"{} {} {}\".format(endYr,endMonth,endDay))\n",
    "\n",
    "startDate = 20010101\n",
    "try:\n",
    "    startDate = loadLastSearchDate()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "endDate = endYr+endMonth+endDay\n",
    "# 아래 검색데이터 저장 완료 후\n",
    "# 현재 종료점(endDate)를 saveLastSearchDate를 호출하여 저장해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [추가] 3. 파라미터정보 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 품질검사성적서 등록정보 전용 스크랩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlencode, quote_plus, unquote\n",
    "import os\n",
    "import time\n",
    "\n",
    "STDENCODING=\"utf-8\"\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "### 파마리터정의: \n",
    "###   - inurl: 메타정보의 \"URL\"컬럼값 (예: https://www.calspia.go.kr/io/openapi/cm/selectIoCmConstructionList.do )\n",
    "###   - inSiteName: 메타정보의 \"자료대상\" (예: 건설사업정보시스템)\n",
    "###   - inDataName: 메타정보의 \"자료명\" (예: 공사정보 목록)\n",
    "###   - inServiceName: 메타정보의 \"기본키\" (예: serviceKey + Format)\n",
    "###   - inParam: 메타정보의 \"파라미터 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "###   - inPageYn: 메타정보의 \"페이지 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "def myscrapy(inUrl, inSiteName, inDataName, inServiceName, inParam, inPageYn, jsonkey=\"items\", dummy=0, inType=\"jsonabnormal\"):\n",
    "    try:\n",
    "        emptyPd = pd.DataFrame()\n",
    "        i=1\n",
    "        while True:\n",
    "            time.sleep(1.2)\n",
    "            print(\"{} page scraping start\".format(i))\n",
    "            \n",
    "            if(inPageYn==1):\n",
    "                inParam[\"pageNo\"] = i\n",
    "            queryParams = '?' + urlencode(inParam)\n",
    "            requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "            response = requests.get(inUrl+queryParams,verify=False)\n",
    "            response.encoding=STDENCODING\n",
    "            rowData = pd.DataFrame()\n",
    "            if(inType==\"jsonabnormal\"):\n",
    "                # 비정상 데이터는 response 섹션이 없음\n",
    "                if(response.json().get('response') == None):\n",
    "                    jsondata = response.json()[\"header\"][\"resultMsg\"]\n",
    "                    if( jsondata != \"NORMAL_SERVICE\"):\n",
    "                        print(\"SERVER ERROR \",jsondata)\n",
    "                        break\n",
    "                    \n",
    "#               여기서부터는 데이터는 있는데, totalcount>0 경우는 items 정보에 세부정보가 더 있음\n",
    "               \n",
    "                jsondata = response.json()[\"response\"][\"body\"][jsonkey]\n",
    "                if( jsondata == []):\n",
    "                    print(\"{} page is empty\".format(i))\n",
    "                    break\n",
    "                if( jsonkey == \"detail1\"):\n",
    "                    jsondata[\"index\"]=[0]\n",
    "                rowData = pd.DataFrame(jsondata)\n",
    "                emptyPd = emptyPd.append(rowData)\n",
    "\n",
    "                \n",
    "                if(0 < int(response.json()[\"response\"][\"body\"][\"totalCount\"])):\n",
    "                    global g_totalCount\n",
    "                    if g_totalCount == 0:\n",
    "                        print(\">totalCount \"+str(response.json()[\"response\"][\"body\"][\"totalCount\"]))\n",
    "                        g_totalCount = int(response.json()[\"response\"][\"body\"][\"totalCount\"])\n",
    "            else:\n",
    "                print(\"Error\")          \n",
    "     \n",
    "            if(inPageYn == 0):\n",
    "                print(\"{} no pageNo\".format(inPageYn))\n",
    "                break\n",
    "            i = i+1\n",
    "\n",
    "        emptyPd.columns = emptyPd.columns.str.lower()\n",
    "        emptyPd.shape\n",
    "#         print(\"dataframe{}, param:{} rows: {} completed\".format(inDataName,inParam, emptyPd.shape[1] )     )\n",
    "        return emptyPd       \n",
    "    except Exception as e:\n",
    "            print(e)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDfMerged = pd.DataFrame()\n",
    "g_totalCount = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "# 파라미터 정보가 기존에 요청했던 정보에 포함되었는지 검사하는 함수\n",
    "# 리턴값 -1 : 파일이 없을 경우\n",
    "#       0 : 파일은 정상존재하나, 요청한적 없는 경우\n",
    "#       1 : 이미 요청했던 경우\n",
    "# 시공자명, 검색시작일, 검색종료일\n",
    "def checkExistenceData(cstrnm, start, end, pageNo):\n",
    "    print(\"{},{},{},{}\".format(cstrnm, start, end, pageNo))\n",
    "    m = hashlib.sha256()\n",
    "    m.update((cstrnm+start+end+str(pageNo)).encode('utf-8'))\n",
    "    print(m.hexdigest())\n",
    "    try:\n",
    "        orgParam = cf.loadparam(SITENAME,DATANAME,SERVICENAME)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1\n",
    "    if m.hexdigest() in orgParam:\n",
    "        print(\"이미 존재함\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# 요청 파라미터를 저장하는 함수\n",
    "# 시공자명, 검색시작일, 검색종료일\n",
    "def hashSaveParam(cstrnm, start, end, pageNo):\n",
    "    print(\"{},{},{},{}\".format(cstrnm, start, end, pageNo))\n",
    "    m = hashlib.sha256()\n",
    "    m.update((cstrnm+start+end+str(pageNo)).encode('utf-8'))\n",
    "    print(m.hexdigest())\n",
    "    orgParam = []\n",
    "    try:\n",
    "        orgParam = cf.loadparam(SITENAME,DATANAME,SERVICENAME)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        newParam = []\n",
    "        newParam.append(m.hexdigest())\n",
    "        saveList = orgParam + newParam\n",
    "        cf.saveparam(saveList, SITENAME,DATANAME,SERVICENAME)\n",
    "        print(\"saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현대건설(주) <> 0\n",
      "BASEPARAM  {'serviceKey': '0974320D-C689-4543-8464-10DE1E5505A9', 'searchCstrNm': '현대건설(주)', 'searchRpcdIsBgDt': '20220427', 'searchRpcdIsEdDt': '20220428', 'sortField': 'tstBgDt', 'pageNo': 1, 'numOfRows': 1000, 'type': 'json'}\n",
      "1 page scraping start\n",
      "1 page is empty\n",
      "No Data\n",
      "일신종합건설㈜ <> 1\n",
      "BASEPARAM  {'serviceKey': '49099D1D-E565-48E1-8A6F-D5F47135EA34', 'searchCstrNm': '일신종합건설㈜', 'searchRpcdIsBgDt': '20220427', 'searchRpcdIsEdDt': '20220428', 'sortField': 'tstBgDt', 'pageNo': 1, 'numOfRows': 1000, 'type': 'json'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-08db21f9b763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mBASEPARAM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"serviceKey\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAPIKEY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapiNo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"searchCstrNm\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msearchCstrNm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"searchRpcdIsBgDt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstartDate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"searchRpcdIsEdDt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mendDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sortField\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"tstBgDt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pageNo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpageNo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numOfRows'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumOfRows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BASEPARAM \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBASEPARAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mresultDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyscrapy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSITENAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDATANAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSERVICENAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBASEPARAM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPAGEYN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSONKEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDUMMY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jsonabnormal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresultDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 정상 데이터가 없는 경우\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-06d251dddf76>\u001b[0m in \u001b[0;36mmyscrapy\u001b[0;34m(inUrl, inSiteName, inDataName, inServiceName, inParam, inPageYn, jsonkey, dummy, inType)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} page scraping start\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import pygame\n",
    "# import math\n",
    "# import numpy as np\n",
    "\n",
    "numOfRows = 1000 # 서버에서 최대 응답 가능한 row임\n",
    "resultDf = pd.DataFrame()\n",
    "recordIdx = 0\n",
    "for i in range(0,dfCombiLen): \n",
    "    searchCstrNm = dfCombi.loc[i].cstrnm\n",
    "    pageNo = 1\n",
    "    print(searchCstrNm,\"<>\",i)\n",
    "\n",
    "    if searchCstrNm != searchCstrNm:\n",
    "        print(\"Nan Case\")\n",
    "        continue\n",
    "    if len(searchCstrNm) <= 1:\n",
    "        print(\"건설사명 이상: \",searchCstrNm)\n",
    "        continue\n",
    "#     print(searchCstrNm,\"<>\",i)\n",
    "    g_totalCount = 0\n",
    "    while True:\n",
    "        apiNo = i%APIKEYLEN\n",
    "\n",
    "        BASEPARAM={\"serviceKey\":APIKEY[apiNo],\"searchCstrNm\": searchCstrNm, \"searchRpcdIsBgDt\": startDate,\"searchRpcdIsEdDt\": endDate, \"sortField\": \"tstBgDt\",\"pageNo\": pageNo, 'numOfRows':numOfRows, \"type\":\"json\"}\n",
    "        print(\"BASEPARAM \",BASEPARAM)\n",
    "        resultDf = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN, JSONKEY, DUMMY, \"jsonabnormal\")\n",
    "        if resultDf.empty: # 정상 데이터가 없는 경우\n",
    "            print(\"No Data\")\n",
    "            break\n",
    "        else:\n",
    "#                 print(resultDf)\n",
    "            resultDfMerged = resultDfMerged.append(resultDf) \n",
    "#             hashSaveParam(searchCstrNm,str(startYr)+\"0101\", str(endYr)+\"1231\", pageNo) # 해시값을 요청 param에 저장\n",
    "            g_totalCount -= numOfRows\n",
    "            print(\"Remain Count : \", g_totalCount)\n",
    "            if(g_totalCount <= 0):    \n",
    "                recordIdx = i\n",
    "                break\n",
    "            pageNo += 1\n",
    "print(\"FINISHED\")\n",
    "# pygame.init()\n",
    "# pygame.mixer.init()\n",
    "# sounda= pygame.mixer.Sound(\"../test.wav\")\n",
    "# sounda.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품질검사성적서 등록 목록 save compled\n"
     ]
    }
   ],
   "source": [
    "cf.savedata(resultDfMerged, SITENAME,DATANAME,SERVICENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488537, 27)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDfMerged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 회차 수행을 위해 현재 검색일자(종료점)를 저장한다. \n",
    "### 다음 회차 검색은 현재 저장한 검색일자가 시작점이 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 파라미터 저장\n",
    "# endDate = \"20220425\" # <- 최초 적재 완료후 주석 처리 예정\n",
    "saveLastSearchDate(endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 데이터 적재분에 대한 기록 \n",
    "# 시공사명 12000개, 2001년 ~ 2022년 4월 25일까지 적재한 기록을 CSV파일로 기록해 둠\n",
    "\n",
    "# dfCombi = dfCombi.iloc[0:recordIdx]\n",
    "\n",
    "# dfCombi['lstSrchDate'] = list(endDate for _ in range(dfCombi.shape[0]))  \n",
    "# saveLastSearchDateByName(dfCombi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
