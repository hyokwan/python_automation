{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시설물 점검진단이력 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/건설사업정보시스템/시설물 점검진단이력 목록/selectIoFmChckDinsHstList.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common import commonFunc as cf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "metadata = pd.read_excel(\"../input/datalake_meta22.xlsx\")\n",
    "\n",
    "SITENAME = \"건설사업정보시스템\"\n",
    "DATANAME= \"시설물 점검진단이력 목록\"\n",
    "with open(\"../input/calsapikey.pickle\",\"rb\") as fr:\n",
    "    APIKEY = pickle.load(fr)\n",
    "\n",
    "targetData = metadata.loc[metadata.자료명==DATANAME]\n",
    "preSetFolder = targetData[\"저장폴더\"].values[0]\n",
    "\n",
    "preSetFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKEYLEN = len(APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 시설물 점검진단계획목록 수\n",
    "g_totalCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'selectIoFmChckDinsHstList'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### 파라미터 설정 #####\n",
    "URL = targetData[\"URL\"].values[0]\n",
    "SERVICENAME = targetData[\"서비스키\"].values[0]\n",
    "SERVICENAME = SERVICENAME.split(\".\")[0]\n",
    "SERVICENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONKEY = \"detail1\"\n",
    "DUMMY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임시 \n",
    "imsiDf = pd.read_csv(\\\n",
    "         \"../output/건설사업정보시스템/시설물 목록/selectIoFmMngList.csv\", encoding=\"ms949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCombi = imsiDf.loc[:,[\"fcno\"]].drop_duplicates()\n",
    "dfCombi.reset_index(inplace=True, drop=True)\n",
    "dfCombiLen = dfCombi.shape[0]\n",
    "dfCombiLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newParam = dfCombi.fcno.drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../output/건설사업정보시스템/시설물 점검진단이력 목록/selectIoFmChckDinsHstList.pickle'\n",
      "시설물 점검진단이력 목록 정보 new 모드 2 \n"
     ]
    }
   ],
   "source": [
    "orgParam = []\n",
    "try:\n",
    "    # 기존 데이터 및 파라미터 정보 불러오기\n",
    "    # 리스트로 불러오기로 변경 0425\n",
    "    orgParam = cf.loadparam(SITENAME,DATANAME,SERVICENAME)[0]\n",
    "## 파일이 없는경우\n",
    "except Exception as e:\n",
    "    orgParam = []\n",
    "    print(e)\n",
    "\n",
    "ptlcmnoList = list( set(newParam) - set(orgParam) )\n",
    "# 모드: 0=종료 1=append 2=새로생성\n",
    "mode = 2\n",
    "\n",
    "# 업데이트 할 내용이 없으면 종료\n",
    "if ptlcmnoList == []:\n",
    "    mode = 0\n",
    "    print(\"{} 정보 quit모드 {} \".format(DATANAME, mode))\n",
    "    quit()\n",
    "# orgParam == []\n",
    "elif orgParam == []:\n",
    "    mode = 2\n",
    "    print(\"{} 정보 new 모드 {} \".format(DATANAME, mode))\n",
    "# 이외에는 append 모드\n",
    "else:\n",
    "    mode = 1\n",
    "    print(\"{} 정보 append 모드 {} \".format(DATANAME, mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시설물 점검진단계획 목록 전용 스크랩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlencode, quote_plus, unquote\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "STDENCODING=\"utf-8\"\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "### 파마리터정의: \n",
    "###   - inurl: 메타정보의 \"URL\"컬럼값 (예: https://www.calspia.go.kr/io/openapi/cm/selectIoCmConstructionList.do )\n",
    "###   - inSiteName: 메타정보의 \"자료대상\" (예: 건설사업정보시스템)\n",
    "###   - inDataName: 메타정보의 \"자료명\" (예: 공사정보 목록)\n",
    "###   - inServiceName: 메타정보의 \"기본키\" (예: serviceKey + Format)\n",
    "###   - inParam: 메타정보의 \"파라미터 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "###   - inPageYn: 메타정보의 \"페이지 정보\" (예: 페이지 파라미터 존재 시 1 값\")\n",
    "### 함수정의: 사이트 메타정보를 받아 데이터를 수집 후 수집결과를 반환하는 함수\n",
    "def myscrapy(inUrl, inSiteName, inDataName, inServiceName, inParam, inPageYn,inAPIKey, inApiCall, jsonkey=\"items\", dummy=0, inType=\"jsonabnormal\"):\n",
    "    try:\n",
    "        emptyPd = pd.DataFrame()\n",
    "        i=1\n",
    "        inAPIKeyLen = len(inAPIKey)\n",
    "        while True:\n",
    "            inApiCall = inApiCall + 1\n",
    "            if inType == \"jsonabnormal\":\n",
    "                time.sleep(1)\n",
    "            inParam[\"serviceKey\"] = inAPIKey[inApiCall%inAPIKeyLen]\n",
    "            print(\"{} page scraping start apicall iter: {} / used {}\".format(i,inApiCall,inParam[\"serviceKey\"]))\n",
    "            \n",
    "            if(inPageYn==1):\n",
    "                inParam[\"pageNo\"] = i\n",
    "            queryParams = '?' + urlencode(inParam)\n",
    "            requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "            response = requests.get(inUrl+queryParams,verify=False)\n",
    "            response.encoding=STDENCODING\n",
    "            rowData = pd.DataFrame()\n",
    "            if(inType==\"jsonabnormal\"):\n",
    "                # 비정상 데이터는 response 섹션이 없음\n",
    "                if(response.json().get('response') == None):\n",
    "                    jsondata = response.json()[\"header\"][\"resultMsg\"]\n",
    "                    if( jsondata == \"NODATA_ERROR\"):\n",
    "                        print(\"{} page is empty\".format(i))\n",
    "                        break\n",
    "                    elif( jsondata == \"DB_ERROR\"):\n",
    "                        print(\"DB ERROR\")\n",
    "                        break\n",
    "                    \n",
    "#               여기서부터는 데이터는 있는데, totalcount>0 경우는 detailList1~5까지 봐야 한다.\n",
    "               \n",
    "                jsondata = response.json()[\"response\"][\"body\"][jsonkey]\n",
    "                if( jsondata == []):\n",
    "                    print(\"{} page is empty\".format(i))\n",
    "                    break\n",
    "                if( jsonkey == \"detail1\"):\n",
    "                    jsondata[\"index\"]=[0]\n",
    "                rowData = pd.DataFrame(jsondata)\n",
    "                emptyPd = emptyPd.append(rowData)\n",
    "                # fcno를 키로 기본정보와 시설물정보를 merge하기 위함\n",
    "                print(\"fcno \",emptyPd['fcno'].values[0])\n",
    "                fcno = emptyPd['fcno'].values[0]\n",
    "                print(\">totalCount \"+str(response.json()[\"response\"][\"body\"][\"totalCount\"]))\n",
    "                if(0 < int(response.json()[\"response\"][\"body\"][\"totalCount\"])):\n",
    "                    global g_totalCount\n",
    "                    if g_totalCount == 0:\n",
    "                        g_totalCount = int(response.json()[\"response\"][\"body\"][\"totalCount\"])\n",
    "                    jsondata = response.json()[\"response\"][\"body\"][\"items\"]\n",
    "                    if( jsondata == []):\n",
    "                        print(\"items is empty\")\n",
    "                    else:\n",
    "#                         jsondata[\"index\"]=[0]\n",
    "                        rowData = pd.DataFrame(jsondata)\n",
    "                        \n",
    "                        rowData['fcno'] = fcno # 시설물 정보에 fcno칼럼을 수동으로 추가 (머지키로 활용하기 위함)\n",
    "                        #emptyPd = pd.concat([emptyPd,rowData],axis=1).reindex(emptyPd.index)\n",
    "                        emptyPd = pd.merge(left = emptyPd , right = rowData, on = \"fcno\")\n",
    "                    \n",
    "            else:\n",
    "                print(\"Error\")          \n",
    "     \n",
    "            if(inPageYn == 0):\n",
    "                print(\"{} no pageNo\".format(inPageYn))\n",
    "                break\n",
    "            i = i+1\n",
    "\n",
    "        emptyPd.columns = emptyPd.columns.str.lower()\n",
    "        emptyPd.shape\n",
    "#         print(\"dataframe{}, param:{} rows: {} completed\".format(inDataName,inParam, emptyPd.shape[1] )     )\n",
    "        return [emptyPd,i,inApiCall]       \n",
    "    except Exception as e:\n",
    "            print(e)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numOfRows = 1000\n",
    "PAGEYN=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0  fcnoValue=  9CC78DF36BD2194BE0440003BA816705\n",
      "1 page scraping start apicall iter: 1 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  9CC78DF36BD2194BE0440003BA816705\n",
      ">totalCount 41\n",
      "0 no pageNo\n",
      "g_totalCount :  -959  numOfRows :  1000\n",
      "i= 1  fcnoValue=  66187B0C116C2893E054B099289CEB28\n",
      "1 page scraping start apicall iter: 2 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  66187B0C116C2893E054B099289CEB28\n",
      ">totalCount 8\n",
      "0 no pageNo\n",
      "g_totalCount :  -992  numOfRows :  1000\n",
      "i= 2  fcnoValue=  F5A4806521451356E044B099289CEB28\n",
      "1 page scraping start apicall iter: 3 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  F5A4806521451356E044B099289CEB28\n",
      ">totalCount 16\n",
      "0 no pageNo\n",
      "g_totalCount :  -984  numOfRows :  1000\n",
      "i= 3  fcnoValue=  0C1C5ACE4FCA7343E0440003BA816705\n",
      "1 page scraping start apicall iter: 4 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  0C1C5ACE4FCA7343E0440003BA816705\n",
      ">totalCount 108\n",
      "0 no pageNo\n",
      "g_totalCount :  -892  numOfRows :  1000\n",
      "i= 4  fcnoValue=  017E09156D16B8E364A7E4A09000D84B\n",
      "1 page scraping start apicall iter: 5 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  017E09156D16B8E364A7E4A09000D84B\n",
      ">totalCount 0\n",
      "0 no pageNo\n",
      "g_totalCount :  -1000  numOfRows :  1000\n",
      "i= 5  fcnoValue=  0A64DE50B08A18C1E054B099289CEB28\n",
      "1 page scraping start apicall iter: 6 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  0A64DE50B08A18C1E054B099289CEB28\n",
      ">totalCount 18\n",
      "0 no pageNo\n",
      "g_totalCount :  -982  numOfRows :  1000\n",
      "i= 6  fcnoValue=  623D10DBC5CB2FF8E0440003BA816705\n",
      "1 page scraping start apicall iter: 7 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  623D10DBC5CB2FF8E0440003BA816705\n",
      ">totalCount 64\n",
      "0 no pageNo\n",
      "g_totalCount :  -936  numOfRows :  1000\n",
      "i= 7  fcnoValue=  5969EF4579124a1b8912EF8C060A4613\n",
      "1 page scraping start apicall iter: 8 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  5969EF4579124a1b8912EF8C060A4613\n",
      ">totalCount 39\n",
      "0 no pageNo\n",
      "g_totalCount :  -961  numOfRows :  1000\n",
      "i= 8  fcnoValue=  EFE3B42F11A00191E0340003BA2D2647\n",
      "1 page scraping start apicall iter: 9 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  EFE3B42F11A00191E0340003BA2D2647\n",
      ">totalCount 118\n",
      "0 no pageNo\n",
      "g_totalCount :  -882  numOfRows :  1000\n",
      "i= 9  fcnoValue=  64E769EA2B6C5B99E054B099289CEB28\n",
      "1 page scraping start apicall iter: 10 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  64E769EA2B6C5B99E054B099289CEB28\n",
      ">totalCount 4\n",
      "0 no pageNo\n",
      "g_totalCount :  -996  numOfRows :  1000\n",
      "i= 10  fcnoValue=  9BABCAD7F8125D97E0440003BA816705\n",
      "1 page scraping start apicall iter: 11 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  9BABCAD7F8125D97E0440003BA816705\n",
      ">totalCount 46\n",
      "0 no pageNo\n",
      "g_totalCount :  -954  numOfRows :  1000\n",
      "i= 11  fcnoValue=  9BAC7A8229016658E0440003BA816705\n",
      "1 page scraping start apicall iter: 12 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  9BAC7A8229016658E0440003BA816705\n",
      ">totalCount 43\n",
      "0 no pageNo\n",
      "g_totalCount :  -957  numOfRows :  1000\n",
      "i= 12  fcnoValue=  E673B64275781C52E034080020A9316A\n",
      "1 page scraping start apicall iter: 13 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  E673B64275781C52E034080020A9316A\n",
      ">totalCount 48\n",
      "0 no pageNo\n",
      "g_totalCount :  -952  numOfRows :  1000\n",
      "i= 13  fcnoValue=  F0217F5F782A09BDE0340003BA2D2647\n",
      "1 page scraping start apicall iter: 14 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  F0217F5F782A09BDE0340003BA2D2647\n",
      ">totalCount 108\n",
      "0 no pageNo\n",
      "g_totalCount :  -892  numOfRows :  1000\n",
      "i= 14  fcnoValue=  E673B6426CFC1C52E034080020A9316A\n",
      "1 page scraping start apicall iter: 15 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  E673B6426CFC1C52E034080020A9316A\n",
      ">totalCount 96\n",
      "0 no pageNo\n",
      "g_totalCount :  -904  numOfRows :  1000\n",
      "i= 15  fcnoValue=  E673B642748F1C52E034080020A9316A\n",
      "1 page scraping start apicall iter: 16 / used 0974320D-C689-4543-8464-10DE1E5505A9\n",
      "fcno  E673B642748F1C52E034080020A9316A\n",
      ">totalCount 73\n",
      "0 no pageNo\n",
      "g_totalCount :  -927  numOfRows :  1000\n",
      "i= 16  fcnoValue=  68850AB707132ACFE0440003BA816705\n",
      "1 page scraping start apicall iter: 17 / used 49099D1D-E565-48E1-8A6F-D5F47135EA34\n",
      "fcno  68850AB707132ACFE0440003BA816705\n",
      ">totalCount 67\n",
      "0 no pageNo\n",
      "g_totalCount :  -933  numOfRows :  1000\n",
      "i= 17  fcnoValue=  47D85E84E12F65EAE054B099289CEB28\n"
     ]
    }
   ],
   "source": [
    "resultDfMerged = pd.DataFrame()\n",
    "resultDf = pd.DataFrame()\n",
    "\n",
    "APICALL = 0 #추가\n",
    "ptlcmnoListLen = len(ptlcmnoList)\n",
    "pageList = [] #추가\n",
    "\n",
    "for i in range(0,ptlcmnoListLen):\n",
    "#     fcnoValue = dfCombi.loc[i].fcno\n",
    "    pageNo = 1\n",
    "    global g_totalCount\n",
    "    g_totalCount = 0\n",
    "    print(\"i=\",i,\" fcnoValue= \",ptlcmnoList[i])\n",
    "    while True:\n",
    "        BASEPARAM={\"serviceKey\":APIKEY[0],\"pageNo\": pageNo, 'fcno':ptlcmnoList[i], 'numOfRows':numOfRows, \"type\":\"json\"}\n",
    "        scrapyResult = myscrapy(URL,SITENAME,DATANAME,SERVICENAME,BASEPARAM,PAGEYN,APIKEY,APICALL, JSONKEY, DUMMY)\n",
    "        resultDf = scrapyResult[0]\n",
    "        pageList.append( scrapyResult[1] )\n",
    "        APICALL = scrapyResult[2]\n",
    "        if resultDf.empty: # 정상 데이터가 없는 경우\n",
    "            break\n",
    "        else:\n",
    "            resultDfMerged = resultDfMerged.append(resultDf) \n",
    "            g_totalCount -= numOfRows\n",
    "            print(\"g_totalCount : \", g_totalCount, \" numOfRows : \", numOfRows)\n",
    "            if(g_totalCount <= 0):\n",
    "                break\n",
    "            pageNo += 1\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 26)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDfMerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시설물 점검진단계획 목록 save compled\n"
     ]
    }
   ],
   "source": [
    "cf.savedata(resultDfMerged, SITENAME,DATANAME,SERVICENAME,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 26)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDfMerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존사용된 파라미터 정보에 추가 파라미터 append 후 저장\n",
    "ptlcmnoList = orgParam + ptlcmnoList\n",
    "\n",
    "paramList = [ptlcmnoList,pageList]\n",
    "# 최종 파라미터 저장\n",
    "cf.saveparam(paramList, SITENAME,DATANAME,SERVICENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
